import os
import yaml
import logging
import pandas as pd
from src.db_mssql import MssqlClient
from src.db_bigquery import BigQueryClient
from src.state_manager import StateManager

# Setup Logging
logging.basicConfig(level=logging.INFO)

# Config
BQ_PROJECT = os.environ.get("BQ_PROJECT")
STATE_BUCKET = os.environ.get("STATE_BUCKET") # Bucket lÆ°u state file

def load_config():
    with open("config/tables.yaml", "r") as f:
        return yaml.safe_load(f)

def process_table(config, mssql, bq, state_mgr):
    table_name = config['source_table']
    bq_dataset = config['bq_dataset']
    bq_table = config['bq_table']
    pk = config['primary_key']

    logging.info(f"--- Processing {table_name} ---")
    
    # 1. Láº¥y Max LSN hiá»‡n táº¡i (Äá»ƒ Ä‘Ã¡nh dáº¥u má»‘c sau khi load xong)
    current_max_lsn = mssql.get_max_lsn()

    # 2. Kiá»ƒm tra báº£ng trÃªn BigQuery Ä‘Ã£ tá»“n táº¡i chÆ°a?
    # LÆ°u Ã½: Cáº§n Ä‘áº£m báº£o file src/db_bigquery.py Ä‘Ã£ cÃ³ hÃ m check_table_exists
    table_exists = bq.check_table_exists(bq_dataset, bq_table)

    df = pd.DataFrame()

    if not table_exists:
        # --- TRÆ¯á»œNG Há»¢P 1: INITIAL LOAD (Load toÃ n bá»™) ---
        logging.info(f"ğŸš€ Table {bq_table} not found. Fetching FULL SNAPSHOT from source...")
        
        # LÆ°u Ã½: Cáº§n Ä‘áº£m báº£o file src/db_mssql.py Ä‘Ã£ cÃ³ hÃ m get_initial_snapshot
        df = mssql.get_initial_snapshot(table_name)
    
    else:
        # --- TRÆ¯á»œNG Há»¢P 2: INCREMENTAL LOAD (Cháº¡y CDC) ---
        start_lsn = state_mgr.get_last_lsn(bq_table)
        
        if start_lsn is None:
            # Báº£ng cÃ³ nhÆ°ng máº¥t file state -> Láº¥y tá»« Min LSN cá»§a há»‡ thá»‘ng
            logging.warning(f"State file missing for {bq_table}. Fallback to Min LSN.")
            capture_instance = table_name.replace('.', '_')
            start_lsn = mssql.get_min_lsn(capture_instance)
        
        if start_lsn == current_max_lsn:
            logging.info("âœ… No new changes found on SQL Server.")
            return

        logging.info(f"ğŸ”„ Fetching changes from {start_lsn.hex()} to {current_max_lsn.hex()}")
        df = mssql.get_changes(table_name, start_lsn, current_max_lsn)

    # Kiá»ƒm tra náº¿u DataFrame rá»—ng
    if df.empty:
        logging.info("âš ï¸ No rows returned from SQL Server.")
        # Váº«n lÆ°u state Ä‘á»ƒ láº§n sau khÃ´ng pháº£i check láº¡i Ä‘oáº¡n nÃ y
        state_mgr.save_state(bq_table, current_max_lsn)
        return

    # 3. Chuáº©n hÃ³a dá»¯ liá»‡u
    # Äá»•i tÃªn cá»™t há»‡ thá»‘ng __$ thÃ nh cdc_ (VÃ¬ BQ khÃ´ng há»— trá»£ kÃ½ tá»± $)
    df.columns = [col.replace('__$', 'cdc_') for col in df.columns]

    # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u Binary (nhÆ° LSN) sang Hex String Ä‘á»ƒ lÆ°u Ä‘Æ°á»£c vÃ o BigQuery
    for col in df.columns:
        if df[col].dtype == 'object' and len(df) > 0:
             # Láº¥y máº«u dÃ²ng Ä‘áº§u tiÃªn Ä‘á»ƒ check kiá»ƒu dá»¯ liá»‡u
             first_val = df[col].iloc[0]
             if isinstance(first_val, bytes):
                 df[col] = df[col].apply(lambda x: x.hex() if isinstance(x, bytes) else x)

    # 4. Load & Merge vÃ o BigQuery
    logging.info(f"ğŸ“¦ Loading {len(df)} rows to BigQuery...")
    bq.load_and_merge(df, bq_dataset, bq_table, pk)

    # 5. LÆ°u State má»›i
    state_mgr.save_state(bq_table, current_max_lsn)
    logging.info(f"ğŸ’¾ Saved state LSN: {current_max_lsn.hex()}")

def main():
    configs = load_config()
    mssql = MssqlClient()
    bq = BigQueryClient(BQ_PROJECT)
    state_mgr = StateManager(STATE_BUCKET)

    for table_conf in configs['tables']:
        if table_conf.get('active', True):
            try:
                process_table(table_conf, mssql, bq, state_mgr)
            except Exception as e:
                logging.error(f"âŒ Failed to sync {table_conf['source_table']}: {e}")
                # KhÃ´ng raise lá»—i Ä‘á»ƒ nÃ³ tiáº¿p tá»¥c cháº¡y cÃ¡c báº£ng khÃ¡c (náº¿u cÃ³)

if __name__ == "__main__":
    main()